{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from surprise import Dataset, Reader, KNNBasic\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "\n",
    "# Sample data: user_id, item_id, rating (could be purchase/view count)\n",
    "data_dict = {\n",
    "    'user_id': [1, 2, 3, 4, 5, 1, 2, 3, 4, 5],\n",
    "    'item_id': [10, 20, 10, 30, 40, 20, 10, 30, 20, 10],\n",
    "    'rating': [5, 4, 3, 2, 5, 4, 3, 5, 2, 4]\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data_dict)\n",
    "\n",
    "# Define a reader with the expected format\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# Load data from DataFrame\n",
    "data = Dataset.load_from_df(df[['user_id', 'item_id', 'rating']], reader)\n",
    "\n",
    "# Split data into train and test sets\n",
    "trainset, testset = train_test_split(data, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.0607\n",
      "RMSE: 1.0606601717798212\n"
     ]
    }
   ],
   "source": [
    "# Use KNNBasic algorithm for collaborative filtering\n",
    "algo = KNNBasic()\n",
    "\n",
    "# Train the algorithm on the trainset\n",
    "algo.fit(trainset)\n",
    "\n",
    "# Test the algorithm on the testset\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "# Calculate and print RMSE\n",
    "rmse = accuracy.rmse(predictions)\n",
    "print(f'RMSE: {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Only 4 items available to recommend.\n",
      "For user_id_1: \n",
      "    Item ID  Estimated Rating\n",
      "0       40          5.000000\n",
      "1       10          4.315789\n",
      "2       20          3.666667\n",
      "3       30          2.000000\n"
     ]
    }
   ],
   "source": [
    "# Function to get top N recommendations for a given user\n",
    "def get_top_n_recommendations(user_id, n):\n",
    "    # Get a list of all item_ids\n",
    "    item_ids = df['item_id'].unique()\n",
    "    \n",
    "    # Predict ratings for all items not yet rated by the user\n",
    "    user_rated_items = df[df['user_id'] == user_id]['item_id']\n",
    "    items_to_predict = [item for item in item_ids if item not in user_rated_items]\n",
    "    \n",
    "    # Handle case where there are not enough items to recommend\n",
    "    if len(items_to_predict) < n:\n",
    "        print(f\"Warning: Only {len(items_to_predict)} items available to recommend.\")\n",
    "    \n",
    "    # Predict ratings for the items\n",
    "    predictions = [algo.predict(user_id, item_id) for item_id in items_to_predict]\n",
    "    \n",
    "    # Sort predictions by estimated rating\n",
    "    predictions.sort(key=lambda x: x.est, reverse=True)\n",
    "    \n",
    "    # Get the top n recommendations\n",
    "    top_n_recommendations = predictions[:n]\n",
    "    \n",
    "    return [(pred.iid, pred.est) for pred in top_n_recommendations]\n",
    "\n",
    "# Get top 10 recommendations for user_id 1\n",
    "user_id = 1\n",
    "recommendations = get_top_n_recommendations(user_id, n=10)\n",
    "\n",
    "# Print recommendations in table format\n",
    "recommendations_df = pd.DataFrame(recommendations, columns=['Item ID', 'Estimated Rating'])\n",
    "print(f\"For user_id_{user_id}: \\n\", recommendations_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## At this point we have a proof-of-concept recommendation model complete. We now need to simply improve on it and get it functionally available for end-users to utilize with an API layer, etc. The DevOps or machine learning or data engineering team will get it into a productionalized / test environment to obtain feedback and the data science team team can start working on ways to improve the model (i.e obtaining more data, different algorithms, hyperparameter tuning, grid search, feature engineering)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
